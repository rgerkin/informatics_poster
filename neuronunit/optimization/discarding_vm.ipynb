{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/mnt/new/informatics_poster/neuronunit/optimization\n",
      "Getting Rheobase cached data value for from AIBS dataset 354190013\n",
      "{'value': array(130.0) * pA}\n",
      "attempting to recover from pickled file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib # Its not that this file is responsible for doing plotting, but it calls many modules that are, such that it needs to pre-empt\n",
    "# setting of an appropriate backend.\n",
    "try:\n",
    "    matplotlib.use('Qt5Agg')\n",
    "except:\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import ipyparallel as ipp\n",
    "\n",
    "from neuronunit import tests\n",
    "\n",
    "\n",
    "rc = ipp.Client(profile='default')\n",
    "rc[:].use_cloudpickle()\n",
    "dview = rc[:]\n",
    "\n",
    "THIS_DIR = os.path.dirname(os.path.realpath('nsga_parallel.py'))\n",
    "this_nu = os.path.join(THIS_DIR,'../../')\n",
    "sys.path.insert(0,this_nu)\n",
    "print(os.getcwd())\n",
    "\n",
    "def re_imports():\n",
    "    THIS_DIR = os.path.dirname(os.path.realpath('nsga_parallel.py'))\n",
    "    this_nu = os.path.join(THIS_DIR,'../../')\n",
    "    sys.path.insert(0,this_nu)\n",
    "    #import get_neab\n",
    "    return\n",
    "\n",
    "dview.apply_sync(re_imports)\n",
    "\n",
    "import get_neab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dview.sync_imports(): # Causes each of these things to be imported on the workers as well as here.\n",
    "    #import get_neab\n",
    "    import matplotlib\n",
    "    import neuronunit\n",
    "    import model_parameters as modelp\n",
    "    try:\n",
    "        matplotlib.use('Qt5Agg') # Need to do this before importing neuronunit on a Mac, because OSX backend won't work\n",
    "    except:\n",
    "        matplotlib.use('Agg') # Need to do this before importing neuronunit on a Mac, because OSX backend won't work\n",
    "                          # on the worker threads.\n",
    "    import pdb\n",
    "    import array\n",
    "    import random\n",
    "    import sys\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import quantities as pq\n",
    "    from deap import algorithms\n",
    "    from deap import base\n",
    "    from deap.benchmarks.tools import diversity, convergence, hypervolume\n",
    "    from deap import creator\n",
    "    from deap import tools\n",
    "\n",
    "\n",
    "    import quantities as qt\n",
    "    import os, sys\n",
    "    import os.path\n",
    "\n",
    "    import deap as deap\n",
    "    import functools\n",
    "    import utilities\n",
    "\n",
    "\n",
    "\n",
    "    import quantities as pq\n",
    "    import neuronunit.capabilities as cap\n",
    "    history = tools.History()\n",
    "    import numpy as np\n",
    "\n",
    "    import sciunit\n",
    "    thisnu = str(os.getcwd())+'/../..'\n",
    "    sys.path.insert(0,thisnu)\n",
    "    import sciunit.scores as scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def p_imports():\n",
    "    from neuronunit.models import backends\n",
    "    from neuronunit.models.reduced import ReducedModel\n",
    "    model = ReducedModel(get_neab.LEMS_MODEL_PATH,name='vanilla',backend='NEURON')\n",
    "    model.load_model()\n",
    "    return\n",
    "\n",
    "dview.apply_sync(p_imports)\n",
    "p_imports()\n",
    "from deap import base\n",
    "from deap import creator\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "class Individual(object):\n",
    "    '''\n",
    "    When instanced the object from this class is used as one unit of chromosome or allele by DEAP.\n",
    "    Extends list via polymorphism.\n",
    "    '''\n",
    "    def __init__(self, *args):\n",
    "        list.__init__(self, *args)\n",
    "        self.error=None\n",
    "        self.results=None\n",
    "        self.name=''\n",
    "        self.attrs = {}\n",
    "        self.params=None\n",
    "        self.score=None\n",
    "        self.fitness=None\n",
    "        self.lookup={}\n",
    "        self.rheobase=None\n",
    "        self.fitness = creator.FitnessMax\n",
    "\n",
    "with dview.sync_imports():\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    import model_parameters as modelp\n",
    "    import numpy as np\n",
    "    BOUND_LOW = [ np.min(i) for i in modelp.model_params.values() ]\n",
    "    BOUND_UP = [ np.max(i) for i in modelp.model_params.values() ]\n",
    "    NDIM = len(BOUND_UP)+1\n",
    "    def uniform(low, up, size=None):\n",
    "        try:\n",
    "            return [random.uniform(a, b) for a, b in zip(low, up)]\n",
    "        except TypeError:\n",
    "            return [random.uniform(a, b) for a, b in zip([low] * size, [up] * size)]\n",
    "\n",
    "\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "    toolbox.register(\"attr_float\", uniform, BOUND_LOW, BOUND_UP, NDIM)\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.attr_float)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "\n",
    "def p_imports():\n",
    "    toolbox = base.Toolbox()\n",
    "    import model_parameters as modelp\n",
    "    import numpy as np\n",
    "    BOUND_LOW = [ np.min(i) for i in modelp.model_params.values() ]\n",
    "    BOUND_UP = [ np.max(i) for i in modelp.model_params.values() ]\n",
    "    NDIM = len(BOUND_UP)+1\n",
    "    def uniform(low, up, size=None):\n",
    "        try:\n",
    "            return [random.uniform(a, b) for a, b in zip(low, up)]\n",
    "        except TypeError:\n",
    "            return [random.uniform(a, b) for a, b in zip([low] * size, [up] * size)]\n",
    "\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "    toolbox.register(\"attr_float\", uniform, BOUND_LOW, BOUND_UP, NDIM)\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.attr_float)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"select\", tools.selNSGA2)\n",
    "    return\n",
    "dview.apply_sync(p_imports)\n",
    "\n",
    "BOUND_LOW = [ np.min(i) for i in modelp.model_params.values() ]\n",
    "BOUND_UP = [ np.max(i) for i in modelp.model_params.values() ]\n",
    "NDIM = len(BOUND_UP)+1 #One extra to store rheobase values in.\n",
    "\n",
    "def uniform(low, up, size=None):\n",
    "    try:\n",
    "        return [random.uniform(a, b) for a, b in zip(low, up)]\n",
    "    except TypeError:\n",
    "        return [random.uniform(a, b) for a, b in zip([low] * size, [up] * size)]\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "toolbox.register(\"attr_float\", uniform, BOUND_LOW, BOUND_UP, NDIM)\n",
    "toolbox.register(\"Individual\", tools.initIterate, creator.Individual, toolbox.attr_float)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.Individual)\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_trans_dict(param_dict):\n",
    "    trans_dict = {}\n",
    "    for i,k in enumerate(list(param_dict.keys())):\n",
    "        trans_dict[i]=k\n",
    "    return trans_dict\n",
    "import model_parameters\n",
    "param_dict = model_parameters.model_params\n",
    "\n",
    "def vm_to_ind(vm,td):\n",
    "\n",
    "    ind =[]\n",
    "    for k in td.keys():\n",
    "        ind.append(vm.attrs[td[k]])\n",
    "    ind.append(vm.rheobase)\n",
    "    from neuronunit.models import backends\n",
    "    from neuronunit.models.reduced import ReducedModel\n",
    "    new_file_path = str(get_neab.LEMS_MODEL_PATH)+str(os.getpid())\n",
    "    model = ReducedModel(new_file_path,name=str('vanilla'),backend='NEURON')\n",
    "    model.load_model()\n",
    "    model.update_run_params(vms.attrs)\n",
    "    return ind\n",
    "\n",
    "\n",
    "\n",
    "def update_pop(pop, trans_dict):\n",
    "\n",
    "    from itertools import repeat\n",
    "    import numpy as np\n",
    "    import copy\n",
    "    pop = [toolbox.clone(i) for i in pop ]\n",
    "    #import utilities\n",
    "    def transform(ind):\n",
    "        from neuronunit.models import backends\n",
    "        from neuronunit.models.reduced import ReducedModel\n",
    "\n",
    "        new_file_path = str(get_neab.LEMS_MODEL_PATH)+str(os.getpid())\n",
    "        model = ReducedModel(new_file_path,name=str('vanilla'),backend='NEURON')\n",
    "        model.load_model()\n",
    "        param_dict = {}\n",
    "        for i,j in enumerate(ind):\n",
    "            param_dict[trans_dict[i]] = str(j)\n",
    "        model.update_run_params(param_dict)\n",
    "        return model\n",
    "\n",
    "    if len(pop) > 0:\n",
    "        models = dview.map_sync(transform, pop)\n",
    "    else:\n",
    "        models = transform(pop)\n",
    "    return models\n",
    "##\n",
    "# Start of the Genetic Algorithm\n",
    "# For good results, MU the size of the gene pool\n",
    "# should at least be as big as number of dimensions/model parameters\n",
    "# explored.\n",
    "##\n",
    "\n",
    "MU = 10\n",
    "NGEN = 7\n",
    "CXPB = 0.9\n",
    "\n",
    "import numpy as np\n",
    "pf = tools.ParetoFront()\n",
    "\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"min\", np.min, axis=0)\n",
    "stats.register(\"max\", np.max, axis=0)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "logbook.header = \"gen\", \"evals\", \"min\", \"max\", \"avg\", \"std\"\n",
    "\n",
    "dview.push({'pf':pf})\n",
    "trans_dict = get_trans_dict(param_dict)\n",
    "td = trans_dict\n",
    "dview.push({'trans_dict':trans_dict,'td':td})\n",
    "\n",
    "pop = toolbox.population(n = MU)\n",
    "\n",
    "pop = [ toolbox.clone(i) for i in pop ]\n",
    "\n",
    "# The part of the code that takes a GENE and translates the GENE into the model it implies.\n",
    "models = update_pop(pop, td)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
